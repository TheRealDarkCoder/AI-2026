{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d39af30",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "## Assignment 5 – Machine Learning\n",
    "\n",
    "### Personal details\n",
    "\n",
    "* **Name:** Ahmed Jabir Zuhayr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df866e02",
   "metadata": {},
   "source": [
    "In this assignment, you will implement a **Naive Bayes** classifier for email spam detection. We will go through the general machine learning pipeline, which in general involves the following steps:\n",
    "\n",
    "1. **Data Preparation**: Load and preprocess the dataset.\n",
    "2. **Feature Extraction**: Convert complex data into numerical features for the model.\n",
    "3. **Model Training**: Train a model to predict the output label of a given input.\n",
    "4. **Model Inference**: Use the trained model to make predictions on new data.\n",
    "5. **Model Optimization**: Fine-tune the model's hyperparameters or compare different models to maximize performance.\n",
    "6. **Model Evaluation**: Use different metrics to evaluate the model's real-world performance.\n",
    "\n",
    "However, some steps may be simplified or skipped entirely depending on the specifics of the problem. As we have chosen to implement a simple Naive Bayes classifier, we will be skipping step 5. Naive Bayes is also a special type of classifier where the feature extraction and model training steps can be thought of as a single combined step, so we will also be skipping step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec72b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f2c92",
   "metadata": {},
   "source": [
    "### 5.1 – Data Preparation\n",
    "\n",
    "We will be using the [Enron-Spam](https://github.com/MWiechmann/enron_spam_data) dataset, which contains a collection of emails labeled as either spam or ham (not spam). The dataset is provided as a CSV file that we will load into a Pandas DataFrame. We encourage you to take a look at the CSV file to understand its structure and the features available for analysis.\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/docs/user_guide/index.html) is a powerful library for data manipulation and analysis in Python. It provides data structures that make it easy to work with structured data. Columns in Pandas are called `Series` objects, and a collection of these is called a `DataFrame`. You can think of a DataFrame as a table where each column can have a different data type (e.g., integers, floats, strings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bdac91",
   "metadata": {},
   "source": [
    "**Task 1: Load the dataset (0.1 pt)**\n",
    "\n",
    "Your first task is to load the dataset in `enron_spam_data.csv` and assign it to the variable `data`. \n",
    "\n",
    "(Hint: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fe8ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Message ID', 'Subject', 'Message', 'Spam/Ham', 'Date'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "data = pd.read_csv(\"enron_spam_data.csv\")\n",
    "\n",
    "# ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "data.dropna(inplace=True) # drop any rows with missing values\n",
    "print(data.columns) # inspect the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae14638",
   "metadata": {},
   "source": [
    "In this assignment we are only concerned with the `Subject`, `Message` and `Spam/ham` columns. These are the inputs and output of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01bad1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22808</th>\n",
       "      <td>re : move</td>\n",
       "      <td>sally ,\\nthe may 18 th date is locked in stone...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22814</th>\n",
       "      <td>steering committee meeting - 07 may 2000</td>\n",
       "      <td>gbn houston steering committee meeting , 07 ma...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19492</th>\n",
       "      <td>goode</td>\n",
       "      <td>gallo , % , online doctors ! herbs , minerals ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>summer intern</td>\n",
       "      <td>we can hire the person as a summer intern\\ndir...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>eastrans - lst of month nomination - eff 8 / 1...</td>\n",
       "      <td>this si to nominate 32 , 800 mmbtu into eastra...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15793</th>\n",
       "      <td>happy new year</td>\n",
       "      <td>attn : sir ,\\ni got to know you through our fo...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>master firm agreements</td>\n",
       "      <td>stacey and ellen :\\nin light of current circum...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11838</th>\n",
       "      <td>change of company number</td>\n",
       "      <td>please note that the company number for enron ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21136</th>\n",
       "      <td>learn fast - earn fast ! we make it easy .</td>\n",
       "      <td>!\\n?\\n.\\n- . / . .\\n. 848\\nn . rainbow blvd . ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20066</th>\n",
       "      <td>buy oem software at massive discounts !</td>\n",
       "      <td>table align = center width = 100 % trtd align ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  \\\n",
       "22808                                          re : move   \n",
       "22814           steering committee meeting - 07 may 2000   \n",
       "19492                                              goode   \n",
       "6017                                       summer intern   \n",
       "1259   eastrans - lst of month nomination - eff 8 / 1...   \n",
       "15793                                     happy new year   \n",
       "13783                             master firm agreements   \n",
       "11838                           change of company number   \n",
       "21136         learn fast - earn fast ! we make it easy .   \n",
       "20066            buy oem software at massive discounts !   \n",
       "\n",
       "                                                 Message Label  \n",
       "22808  sally ,\\nthe may 18 th date is locked in stone...   ham  \n",
       "22814  gbn houston steering committee meeting , 07 ma...   ham  \n",
       "19492  gallo , % , online doctors ! herbs , minerals ...  spam  \n",
       "6017   we can hire the person as a summer intern\\ndir...   ham  \n",
       "1259   this si to nominate 32 , 800 mmbtu into eastra...   ham  \n",
       "15793  attn : sir ,\\ni got to know you through our fo...  spam  \n",
       "13783  stacey and ellen :\\nin light of current circum...   ham  \n",
       "11838  please note that the company number for enron ...   ham  \n",
       "21136  !\\n?\\n.\\n- . / . .\\n. 848\\nn . rainbow blvd . ...  spam  \n",
       "20066  table align = center width = 100 % trtd align ...  spam  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.drop(columns=['Message ID', 'Date']) # drop unnecessary columns\n",
    "data.rename(columns={'Spam/Ham': 'Label'}, inplace=True) # rename the \"Spam/ham\" column to \"Label\"\n",
    "display(data.sample(10, random_state=42)) # display 10 random rows from the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aede0a",
   "metadata": {},
   "source": [
    "**Task 2: Elementary preprocessing (0.1 pt)**\n",
    "\n",
    "It is often desirable to treat textual output labels as numerical values. Your second task is to convert the `Label` column into numerical format, where `ham` is represented as `0` and `spam` as `1`. You may consult the Pandas [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html) on how to replace values (see \"Parameters\" -> \"to_replace\" -> \"dict\").\n",
    "\n",
    "(Hint: note that the `replace` method operates on a `Series` object, not the entire `DataFrame`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad6143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Message</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22808</th>\n",
       "      <td>re : move</td>\n",
       "      <td>sally ,\\nthe may 18 th date is locked in stone...</td>\n",
       "      <td>0</td>\n",
       "      <td>re : move sally ,\\nthe may 18 th date is locke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22814</th>\n",
       "      <td>steering committee meeting - 07 may 2000</td>\n",
       "      <td>gbn houston steering committee meeting , 07 ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>steering committee meeting - 07 may 2000 gbn h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19492</th>\n",
       "      <td>goode</td>\n",
       "      <td>gallo , % , online doctors ! herbs , minerals ...</td>\n",
       "      <td>1</td>\n",
       "      <td>goode gallo , % , online doctors ! herbs , min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>summer intern</td>\n",
       "      <td>we can hire the person as a summer intern\\ndir...</td>\n",
       "      <td>0</td>\n",
       "      <td>summer intern we can hire the person as a summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>eastrans - lst of month nomination - eff 8 / 1...</td>\n",
       "      <td>this si to nominate 32 , 800 mmbtu into eastra...</td>\n",
       "      <td>0</td>\n",
       "      <td>eastrans - lst of month nomination - eff 8 / 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15793</th>\n",
       "      <td>happy new year</td>\n",
       "      <td>attn : sir ,\\ni got to know you through our fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>happy new year attn : sir ,\\ni got to know you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>master firm agreements</td>\n",
       "      <td>stacey and ellen :\\nin light of current circum...</td>\n",
       "      <td>0</td>\n",
       "      <td>master firm agreements stacey and ellen :\\nin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11838</th>\n",
       "      <td>change of company number</td>\n",
       "      <td>please note that the company number for enron ...</td>\n",
       "      <td>0</td>\n",
       "      <td>change of company number please note that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21136</th>\n",
       "      <td>learn fast - earn fast ! we make it easy .</td>\n",
       "      <td>!\\n?\\n.\\n- . / . .\\n. 848\\nn . rainbow blvd . ...</td>\n",
       "      <td>1</td>\n",
       "      <td>learn fast - earn fast ! we make it easy . !\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20066</th>\n",
       "      <td>buy oem software at massive discounts !</td>\n",
       "      <td>table align = center width = 100 % trtd align ...</td>\n",
       "      <td>1</td>\n",
       "      <td>buy oem software at massive discounts ! table ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  \\\n",
       "22808                                          re : move   \n",
       "22814           steering committee meeting - 07 may 2000   \n",
       "19492                                              goode   \n",
       "6017                                       summer intern   \n",
       "1259   eastrans - lst of month nomination - eff 8 / 1...   \n",
       "15793                                     happy new year   \n",
       "13783                             master firm agreements   \n",
       "11838                           change of company number   \n",
       "21136         learn fast - earn fast ! we make it easy .   \n",
       "20066            buy oem software at massive discounts !   \n",
       "\n",
       "                                                 Message  Label  \\\n",
       "22808  sally ,\\nthe may 18 th date is locked in stone...      0   \n",
       "22814  gbn houston steering committee meeting , 07 ma...      0   \n",
       "19492  gallo , % , online doctors ! herbs , minerals ...      1   \n",
       "6017   we can hire the person as a summer intern\\ndir...      0   \n",
       "1259   this si to nominate 32 , 800 mmbtu into eastra...      0   \n",
       "15793  attn : sir ,\\ni got to know you through our fo...      1   \n",
       "13783  stacey and ellen :\\nin light of current circum...      0   \n",
       "11838  please note that the company number for enron ...      0   \n",
       "21136  !\\n?\\n.\\n- . / . .\\n. 848\\nn . rainbow blvd . ...      1   \n",
       "20066  table align = center width = 100 % trtd align ...      1   \n",
       "\n",
       "                                                    Text  \n",
       "22808  re : move sally ,\\nthe may 18 th date is locke...  \n",
       "22814  steering committee meeting - 07 may 2000 gbn h...  \n",
       "19492  goode gallo , % , online doctors ! herbs , min...  \n",
       "6017   summer intern we can hire the person as a summ...  \n",
       "1259   eastrans - lst of month nomination - eff 8 / 1...  \n",
       "15793  happy new year attn : sir ,\\ni got to know you...  \n",
       "13783  master firm agreements stacey and ellen :\\nin ...  \n",
       "11838  change of company number please note that the ...  \n",
       "21136  learn fast - earn fast ! we make it easy . !\\n...  \n",
       "20066  buy oem software at massive discounts ! table ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "data[\"Label\"] = data['Label'].replace({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "data[\"Label\"] = data[\"Label\"].astype(int)  # you can probably ignore any potential warnings due to this line\n",
    "data[\"Text\"] = data[\"Subject\"] + \" \" + data[\"Message\"]\n",
    "display(data.sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2ffeb",
   "metadata": {},
   "source": [
    "We also combined the `Subject` and `Message` columns into a single column called `Text`. This will be the input to our model.\n",
    "\n",
    "Next we need to split our data into training and test sets. The training set will be used to train the model, while the test set will be used to evaluate the model's performance. There are many ways to split the data, but one typical approach is an 80/20 split, meaning 80% of the data will be used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9217adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 26486, test set size: 6621\n"
     ]
    }
   ],
   "source": [
    "data_train = data.sample(frac=0.8, random_state=42) # randomly sample 80% of the data for training\n",
    "data_test = data.drop(data_train.index) # drop the training set from the original data to get the test set\n",
    "\n",
    "print(f\"Training set size: {data_train.shape[0]}, test set size: {data_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47f436",
   "metadata": {},
   "source": [
    "### 5.2 – Feature Extraction\n",
    "\n",
    "If we were dealing with, say, predicting the value of a used car based on simple input data such as year of manufacture and mileage, we could use these values directly as the features for our model. However, often in machine learning we need to *engineer our own features* from raw data, especially when dealing with textual or visual data.\n",
    "\n",
    "We will use the **Bag of Words (BoW)** model to convert our text data into numerical features. The BoW model represents text data as a collection of words, disregarding grammar and word order, but keeping track of the frequency of each word in the document.\n",
    "\n",
    "The basic idea is as follows:\n",
    "\n",
    "1. Create a vocabulary of all unique words in the dataset.\n",
    "2. For each document (subject + message), count the occurrence of each word in the vocabulary.\n",
    "3. Represent each document as a vector of word counts.\n",
    "\n",
    "We can then use these vectors as input for our model. This process can be needlessly arduous as well as computationally expensive if done manually, so we will use a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to handle things for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b64e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'free' in data: 3745 (spam) / 1173 (ham)\n",
      "Frequency of 'schedule' in data: 50 (spam) / 1954 (ham)\n"
     ]
    }
   ],
   "source": [
    "# Fit vectorizer on all training data to get a shared vocabulary\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data_train[\"Text\"])\n",
    "\n",
    "# Get indices for spam and ham\n",
    "spam_idx = (data_train[\"Label\"] == 1).values\n",
    "ham_idx = (data_train[\"Label\"] == 0).values\n",
    "\n",
    "# Get word counts for spam and ham using the same vocabulary\n",
    "spam_counts = X[spam_idx].sum(axis=0).A1  # .A1 flattens to 1D array\n",
    "ham_counts = X[ham_idx].sum(axis=0).A1\n",
    "\n",
    "# Create dictionaries for words and their counts\n",
    "words = vectorizer.get_feature_names_out()\n",
    "spam_words = dict(zip(words, spam_counts))\n",
    "ham_words = dict(zip(words, ham_counts))\n",
    "\n",
    "# Drop all words that are not present\n",
    "spam_words = {word: count for word, count in spam_words.items() if count > 0}\n",
    "ham_words = {word: count for word, count in ham_words.items() if count > 0}\n",
    "\n",
    "# Some example words and their frequencies\n",
    "print(f\"Frequency of 'free' in data: {spam_words.get('free', 0)} (spam) / {ham_words.get('free', 0)} (ham)\")\n",
    "print(f\"Frequency of 'schedule' in data: {spam_words.get('schedule', 0)} (spam) / {ham_words.get('schedule', 0)} (ham)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0045d57",
   "metadata": {},
   "source": [
    "Interpreting feature vectors of this size can get difficult, so you should take a look at the examples in the documentation to get an idea of what the output looks like.\n",
    "\n",
    "(Don't worry if you don't fully understand the details here, feature engineering for text data will be covered in more detail in the Natural Language Processing course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456e3c6",
   "metadata": {},
   "source": [
    "### 5.3 – Model Inference\n",
    "\n",
    "Now that we have our data prepared and features extracted, we can use a Naive Bayes classifier to predict whether an email is spam or ham based on the subject and message.\n",
    "\n",
    "The general form of the Naive Bayes classifier is as follows:\n",
    "\n",
    "$$P(y | w_1, ... , w_i) = \\alpha P(y) \\prod_{i=1}^{n} P(w_i | y)$$\n",
    "\n",
    "where\n",
    "- $P(y)$ is the prior probability of the class $y$ (spam or ham)\n",
    "- $P(w_i | y)$ is the conditional probability of word $w$ at position $i$ given the class $y$\n",
    "- $\\alpha$ is a normalization constant to ensure that the probabilities sum to 1.\n",
    "\n",
    "Note that most of the probabilities $P(w_i | y)$ will be very small, so repeatedly multiplying them together can lead to numerical underflow. We can avoid this by performing the calculations in logarithmic space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e32cc1",
   "metadata": {},
   "source": [
    "**Task 3: Naive Bayes classifier (0.5 pt)**\n",
    "\n",
    "Complete the `naive_bayes` function. You will need to calculate the conditional probabilities of each word given the class label (= how often this word appears in mails of this class) and use these to update the prior probabilities. You also need to handle cases where a word in the mail is not present in the training data to avoid zero division errors: use Laplace smoothing (a.k.a. add-one smoothing) to ensure that every word has a non-zero probability of occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac374c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(spam_logprob, ham_logprob):\n",
    "    \"\"\"\n",
    "    Normalize the log-probabilities using the log-sum-exp trick.\n",
    "    \"\"\"\n",
    "    max_logprob = max(spam_logprob, ham_logprob)\n",
    "    spam_prob = np.exp(spam_logprob - max_logprob)\n",
    "    ham_prob = np.exp(ham_logprob - max_logprob)\n",
    "    norm = spam_prob + ham_prob\n",
    "    spam_prob /= norm\n",
    "    ham_prob /= norm\n",
    "    return spam_prob, ham_prob\n",
    "\n",
    "vocab_size = len(words) # number of unique words in the training data\n",
    "num_of_spam_words = sum(spam_counts)  # total number of words in spam emails\n",
    "num_of_ham_words = sum(ham_counts)    # total number of words in ham emails\n",
    "analyzer = vectorizer.build_analyzer() # used for tokenizing the input text\n",
    "\n",
    "def naive_bayes(message):\n",
    "    # Get the individual words from the input text\n",
    "    input_words = analyzer(message)\n",
    "\n",
    "    # Initialize prior log-probabilities for spam and ham\n",
    "    spam_logprob = np.log(0.5)\n",
    "    ham_logprob = np.log(0.5)\n",
    "\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "    # 1. Loop through the words in the input message\n",
    "    for word in input_words:\n",
    "\n",
    "        # 2. Get the frequencies of the word in spam and ham\n",
    "        # (Hint: check the previous cell for appropriate variables and examples)\n",
    "        spam_word_count = spam_words.get(word, 0)\n",
    "        ham_word_count  = ham_words.get(word, 0)\n",
    "        \n",
    "        # 3. Get the probabilities of the word and apply Laplace smoothing\n",
    "        p_word_spam = (spam_word_count + 1) / (num_of_spam_words + vocab_size)\n",
    "        p_word_ham  = (ham_word_count  + 1) / (num_of_ham_words  + vocab_size)\n",
    "\n",
    "        # 4. Update the prior log-probabilities\n",
    "        # (Hint: remember to stay in log-space and replace products with sums)\n",
    "        spam_logprob += np.log(p_word_spam)\n",
    "        ham_logprob  += np.log(p_word_ham)\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "    # Normalize the log-probabilities\n",
    "    spam_prob, ham_prob = normalize(spam_logprob, ham_logprob)\n",
    "\n",
    "    # Return the normalized probabilities\n",
    "    return {\"P_spam\": spam_prob, \"P_ham\": ham_prob}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d02b0b",
   "metadata": {},
   "source": [
    "Some anecdotal testing can be done by simply coming up with a few test messages and checking the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7724ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating spam message:\n",
      "P(spam): 1.000, P(ham): 0.000\n",
      "\n",
      "Evaluating ambiguous message:\n",
      "P(spam): 0.117, P(ham): 0.883\n",
      "\n",
      "Evaluating ham message:\n",
      "P(spam): 0.000, P(ham): 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_message = \"You are the lucky winner of a million dollars! Claim your prize by visiting our website: www.spammywebsite.com\"\n",
    "\n",
    "ambiguous_message = \"\"\"Weekly update: Our Outlook subscription has been upgraded. New features include: AI-generated meeting summaries, \n",
    "agentic scheduling, and more. Check the full list by clicking here. In other news, we now have a company credit card for all employees\n",
    "to use for business expenses. Click here to learn more.\"\"\"\n",
    "\n",
    "ham_message = \"Hey Tom, I hope you are doing well. I have some updates on the project. Let's catch up over coffee tomorrow? -Clara\"\n",
    "\n",
    "print(\"Evaluating spam message:\")\n",
    "result1 = naive_bayes(spam_message)\n",
    "print(f\"P(spam): {result1['P_spam']:.3f}, P(ham): {result1['P_ham']:.3f}\\n\")\n",
    "print(\"Evaluating ambiguous message:\")\n",
    "result2 = naive_bayes(ambiguous_message)\n",
    "print(f\"P(spam): {result2['P_spam']:.3f}, P(ham): {result2['P_ham']:.3f}\\n\")\n",
    "print(\"Evaluating ham message:\")\n",
    "result3 = naive_bayes(ham_message)\n",
    "print(f\"P(spam): {result3['P_spam']:.3f}, P(ham): {result3['P_ham']:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728c6df",
   "metadata": {},
   "source": [
    "### 5.4 – Model Evaluation\n",
    "\n",
    "More rigorous evaluation of the model can be done using various metrics. Some of the most common metrics for classification tasks are:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP + TN + FP + FN}}$$\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP + FP}} $$\n",
    "$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}} $$\n",
    "\n",
    "where:\n",
    "- TP: True Positives (correctly predicted spam)\n",
    "- TN: True Negatives (correctly predicted ham)\n",
    "- FP: False Positives (ham predicted as spam)\n",
    "- FN: False Negatives (spam predicted as ham)\n",
    "\n",
    "Accuracy can be thought of as the overall correctness of the model irrespective of what types of errors it makes. Precision tells us how many of the predicted spam emails were actually spam, while recall tells us how many of the actual spam emails were correctly caught by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd834d",
   "metadata": {},
   "source": [
    "**Task 4: Evaluation metrics (0.3 pt)**\n",
    "\n",
    "Implement the `precision` and `recall` functions. The inputs to these functions will be the predicted and true labels of the test set and will be provided based on your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d97197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions.\n",
    "    \"\"\"\n",
    "    return sum(predictions == labels) / len(labels)\n",
    "\n",
    "def precision(predictions, labels):\n",
    "    TP = sum((predictions == labels) & (predictions == 1))\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "    FP = sum((predictions != labels) & (predictions == 1))  # predicted spam, actually ham\n",
    "    return TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "def recall(predictions, labels):\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "    TP = sum((predictions == labels) & (predictions == 1))\n",
    "    FN = sum((predictions != labels) & (predictions == 0))  # predicted ham, actually spam\n",
    "    return TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "    # ---------- YOUR CODE HERE ----------- #\n",
    "\n",
    "def classify(message):\n",
    "    \"\"\"\n",
    "    Classify a message as spam (1) or ham (0) using the naive_bayes function.\n",
    "    \"\"\"\n",
    "    result = naive_bayes(message)\n",
    "    return 1 if result['P_spam'] > result['P_ham'] else 0 # return the label with the higher probability\n",
    "\n",
    "def evaluate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Compute and print accuracy, precision, and recall.\n",
    "    \"\"\"\n",
    "    acc = accuracy(predictions, labels)\n",
    "    prec = precision(predictions, labels)\n",
    "    rec = recall(predictions, labels)\n",
    "    print(f\"Accuracy: {acc:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27be39",
   "metadata": {},
   "source": [
    "Running the `evaluate` function will print the accuracy, precision, and recall of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966b4152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987, precision: 0.981, recall: 0.993\n"
     ]
    }
   ],
   "source": [
    "predictions = data_test[\"Text\"].apply(classify)\n",
    "evaluate(predictions, data_test[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d6543",
   "metadata": {},
   "source": [
    "As you will see in other courses, most of the operations we performed in this exercise can be done much more efficiently using libraries such as [scikit-learn](https://scikit-learn.org/stable/getting_started.html), which provide optimized implementations of various machine learning models as well as operations such as data splitting, feature extraction, and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3825660",
   "metadata": {},
   "source": [
    "### EXTRA: Discussion\n",
    "\n",
    "**What would the precision and recall metrics look like if we had a very strict spam filter that classified most emails as spam? If they are in conflict, which metric do you think we should generally optimize for in spam detection? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb353abf",
   "metadata": {},
   "source": [
    "Precision would be low because the filter is trigger-happy, many legitimate ham emails get flagged as spam, driving up FP. Most \"spam\" predictions are wrong.\n",
    "Recall would be high since almost everything is labeled spam, nearly all actual spam emails get caught, so FN is tiny.\n",
    "\n",
    "For spam filters, we should optimize for precision. The cost of a false positive (a legitimate email silently buried in a spam folder) is typically higher than the cost of a false negative (a spam email slipping through). Missing a legitimate email is more dangerious than falsely approving a spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5f61a",
   "metadata": {},
   "source": [
    "## Aftermath\n",
    "\n",
    "Please provide short answers to the following questions:\n",
    "\n",
    "**1. Did you experience any issues or find anything particularly confusing?**\n",
    "\n",
    "No\n",
    "\n",
    "**2. Is there anything you would like to see improved in the assignment?**\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f4214",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "1. Make sure you have completed all tasks and filled in your personal details at the top of this notebook.\n",
    "2. Ensure all the code runs without errors: restart the kernel and run all cells in order.\n",
    "3. Submit *only* this notebook (`ex5.ipynb`) on Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
